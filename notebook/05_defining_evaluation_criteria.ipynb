{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034e4143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import könyvtárak\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics import classification_report, confusion_matrix, mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b304f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model(models_dir: str):\n",
    "    \"\"\"Find and return path to best model checkpoint.\"\"\"\n",
    "    models_path = Path(models_dir)\n",
    "    best_models = list(models_path.glob('best_*.pt'))\n",
    "    if not best_models:\n",
    "        raise FileNotFoundError(f\"No best_*.pt checkpoints found in {models_dir}\")\n",
    "    # Prefer Final_Balanced, fallback to latest\n",
    "    final_balanced = [m for m in best_models if 'final_balanced' in m.name.lower()]\n",
    "    return str(final_balanced[0] if final_balanced else best_models[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ab1652",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDataset(Dataset):\n",
    "    \"\"\"Dataset for transformer inference.\"\"\"\n",
    "    def __init__(self, texts, tokenizer, max_length=384):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d8cdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, labels, save_path):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=labels, yticklabels=labels,\n",
    "           ylabel='True label', xlabel='Predicted label',\n",
    "           title='Confusion Matrix (Test) - Transformer')\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    thresh = cm.max() / 2.0 if cm.size else 0\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], 'd'), ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(save_path, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b9c2a4",
   "metadata": {},
   "source": [
    "## Load Best Model & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64358ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "base_output = os.getenv('OUTPUT_DIR', '../output')\n",
    "processed_dir = os.path.join(base_output, 'processed')\n",
    "models_dir = os.path.join(base_output, 'models')\n",
    "eval_dir = os.path.join(base_output, 'reports')\n",
    "\n",
    "test_path = os.path.join(processed_dir, 'test.csv')\n",
    "\n",
    "Path(eval_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90a30de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf42c20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and load best model checkpoint\n",
    "best_checkpoint_path = find_best_model(models_dir)\n",
    "print(f\"Loading best model checkpoint from {best_checkpoint_path}...\")\n",
    "\n",
    "checkpoint = torch.load(best_checkpoint_path, map_location=device)\n",
    "label2id = checkpoint['label2id']\n",
    "id2label = {int(k): v for k, v in checkpoint['id2label'].items()}\n",
    "\n",
    "print(f\"Label mapping: {id2label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb5178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model architecture (you need to import the model class from 04)\n",
    "# For simplicity, we'll assume we saved the model class in the checkpoint\n",
    "# In practice, you'd import it from the 04 notebook or a shared module\n",
    "\n",
    "# For this example, let's use BalancedFinalModel\n",
    "class BalancedFinalModel(nn.Module):\n",
    "    \"\"\"Final: Balanced - Production-ready model.\"\"\"\n",
    "    def __init__(self, transformer_model, num_classes=5, hidden_dim=256, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.transformer = transformer_model\n",
    "        self.num_classes = num_classes\n",
    "        trans_hidden = transformer_model.config.hidden_size\n",
    "        \n",
    "        self.adapter = nn.Sequential(\n",
    "            nn.Linear(trans_hidden, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.LayerNorm(hidden_dim // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.classifier = nn.Linear(hidden_dim // 2, num_classes)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        outputs = self.transformer(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            output_hidden_states=False,\n",
    "            return_dict=True\n",
    "        )\n",
    "        hidden = outputs.last_hidden_state\n",
    "        \n",
    "        # Mean pooling\n",
    "        mask = attention_mask.unsqueeze(-1)\n",
    "        summed = (hidden * mask).sum(1)\n",
    "        counts = mask.sum(1).clamp(min=1)\n",
    "        pooled = summed / counts\n",
    "        \n",
    "        adapted = self.adapter(pooled)\n",
    "        logits = self.classifier(adapted)\n",
    "        \n",
    "        output = type('Output', (), {'logits': logits})()\n",
    "        if labels is not None:\n",
    "            output.loss = nn.CrossEntropyLoss()(logits, labels)\n",
    "        return output\n",
    "\n",
    "# Load base transformer and create model\n",
    "transformer_model_name = os.getenv('TRANSFORMER_MODEL', 'SZTAKI-HLT/hubert-base-cc')\n",
    "base_transformer = AutoModel.from_pretrained(transformer_model_name)\n",
    "model = BalancedFinalModel(base_transformer, num_classes=len(id2label))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c9ec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(transformer_model_name)\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_csv(test_path)\n",
    "if not {'text', 'label'}.issubset(test_df.columns):\n",
    "    raise ValueError(\"Test CSV must contain 'text' and 'label' columns\")\n",
    "\n",
    "X_test = test_df['text'].astype(str).tolist()\n",
    "y_test = test_df['label'].astype(str).tolist()\n",
    "\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02ae26d",
   "metadata": {},
   "source": [
    "## Run Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7824f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset and dataloader\n",
    "batch_size = int(os.getenv('BATCH_SIZE', '8'))\n",
    "max_length = int(os.getenv('MAX_LENGTH', '384'))\n",
    "test_dataset = TransformerDataset(X_test, tokenizer, max_length)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be73c978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference\n",
    "print(\"Running evaluation on test set...\")\n",
    "y_pred = []\n",
    "disable_tqdm = not sys.stdout.isatty()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Evaluating\", disable=disable_tqdm):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        \n",
    "        y_pred.extend([id2label[int(p)] for p in preds.cpu().numpy()])\n",
    "\n",
    "print(\"Evaluation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96240172",
   "metadata": {},
   "source": [
    "## Generate Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad19898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification report\n",
    "labels = sorted(list(set(y_test) | set(y_pred)))\n",
    "report = classification_report(y_test, y_pred, labels=labels, output_dict=True, zero_division=0)\n",
    "\n",
    "# Add ordinal regression metrics (MAE, RMSE)\n",
    "def labels_to_numeric(labels):\n",
    "    out = []\n",
    "    for l in labels:\n",
    "        m = str(l).strip()\n",
    "        if m and m[0].isdigit():\n",
    "            out.append(int(m[0]))\n",
    "        else:\n",
    "            out.append(0)\n",
    "    return np.array(out)\n",
    "\n",
    "y_true_num = labels_to_numeric(y_test)\n",
    "y_pred_num = labels_to_numeric(y_pred)\n",
    "mae = mean_absolute_error(y_true_num, y_pred_num)\n",
    "rmse = np.sqrt(mean_squared_error(y_true_num, y_pred_num))\n",
    "\n",
    "report['mae'] = float(mae)\n",
    "report['rmse'] = float(rmse)\n",
    "weighted_f1 = report.get('weighted avg', {}).get('f1-score', 0)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"TEST RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Test Accuracy: {report['accuracy']:.4f}\")\n",
    "print(f\"Weighted F1: {weighted_f1:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736b012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display detailed classification report\n",
    "from sklearn.metrics import classification_report as cr_display\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(cr_display(y_test, y_pred, labels=labels, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d76bd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save report\n",
    "report_path = os.path.join(eval_dir, '05-evaluation_test_report.json')\n",
    "with open(report_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(report, f, ensure_ascii=False, indent=2)\n",
    "print(f\"Saved test report to {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42a3cdd",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40a482a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and save confusion matrix\n",
    "cm_path = os.path.join(eval_dir, '05-evaluation_test_confusion_matrix.png')\n",
    "plot_confusion_matrix(y_test, y_pred, labels, cm_path)\n",
    "print(f\"Saved test confusion matrix to {cm_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adc3e84",
   "metadata": {},
   "source": [
    "## Evaluation Complete!\n",
    "\n",
    "A modell értékelése befejezve a test set-en."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
