# Legal Text Decoder - Projekt Architekt√∫ra √©s R√©szletes Dokument√°ci√≥

## üìã Projekt √Åttekint√©s

A **Legal Text Decoder** egy m√©lytanul√°s alap√∫ NLP rendszer, amely automatikusan √©rt√©keli jogi sz√∂vegek (√ÅSZF, √ÅFF) √©rthet≈ës√©g√©t egy 1-5 sk√°l√°n. A projekt Docker kont√©nerben fut, NVIDIA GPU t√°mogat√°ssal.

## üèóÔ∏è Architekt√∫ra

### Komponensek

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Docker Container                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  1. Data Processing (01_data_processing.py)            ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     - JSON bet√∂lt√©s √©s valid√°l√°s                       ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     - Sz√∂veg tiszt√≠t√°s (Unicode, whitespace)           ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     - Stratifik√°lt train/val/test split                ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                           ‚Üì                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  2. Feature Engineering (02_feature_engineering.py)    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     - Sz√∂vegstatisztik√°k (word count, avg word len)    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     - Opcion√°lis Sentence-BERT embeddings              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     - Explorat√≠v adatvizualiz√°ci√≥                      ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                           ‚Üì                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  3. Baseline Model (03_train_baseline.py)             ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     - TF-IDF vektoriz√°ci√≥ (max 20k features)           ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     - Logistic Regression klasszifik√°ci√≥              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     - Sklearn Pipeline                                 ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                           ‚Üì                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  4. Transformer Model (04_train_transformer.py)        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     - HuBERT finomhangol√°s (magyar BERT)               ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     - PyTorch + Transformers library                   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     - GPU akceler√°ci√≥                                  ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                           ‚Üì                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  5. Evaluation (05_evaluation.py)                      ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     - Test set √©rt√©kel√©s                               ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     - Classification report, confusion matrix          ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                           ‚Üì                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  6. Robustness Tests (06_robustness_tests.py)          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     - Zaj-t≈±r√©s tesztel√©s (5%, 10%, 20% noise)         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     - Csonkol√°s tesztel√©s (75%, 50%, 25%)              ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                           ‚Üì                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  7. Explainability (07_explainability.py)              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     - Feature importance elemz√©s                       ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     - Predikci√≥ magyar√°zatok                           ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     - Hibaelemz√©s                                      ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìÅ Projekt Strukt√∫ra

```
DeepLearning_Project-Legal_Text_Decoder/
‚îú‚îÄ‚îÄ Dockerfile                      # Docker k√∂rnyezet defin√≠ci√≥
‚îú‚îÄ‚îÄ requirements.txt                # Python f√ºgg≈ës√©gek
‚îú‚îÄ‚îÄ README.md                       # Projekt dokument√°ci√≥
‚îú‚îÄ‚îÄ ARCHITECTURE.md                 # Ez a f√°jl
‚îú‚îÄ‚îÄ LICENSE                         # Licenc
‚îú‚îÄ‚îÄ .gitignore                      # Git ignore f√°jl
‚îú‚îÄ‚îÄ RUNNING_DOCKERFILE.txt          # Docker futtat√°si utas√≠t√°sok
‚îú‚îÄ‚îÄ training_log.txt               # Pipeline fut√°s logja (gener√°lt)
‚îÇ
‚îú‚îÄ‚îÄ notebook/                       # Jupyter notebookok k√≠s√©rletez√©shez
‚îÇ   ‚îî‚îÄ‚îÄ teszteles.ipynb
‚îÇ
‚îî‚îÄ‚îÄ src/                            # Forr√°sk√≥d
    ‚îú‚îÄ‚îÄ run.sh                      # Pipeline futtat√°si script
    ‚îú‚îÄ‚îÄ 01_data_processing.py       # Adat el≈ëk√©sz√≠t√©s
    ‚îú‚îÄ‚îÄ 02_feature_engineering.py   # Feature extraction
    ‚îú‚îÄ‚îÄ 03_train_baseline.py        # Baseline modell
    ‚îú‚îÄ‚îÄ 04_train_transformer.py     # Transformer modell
    ‚îú‚îÄ‚îÄ 05_evaluation.py            # Ki√©rt√©kel√©s
    ‚îú‚îÄ‚îÄ 06_robustness_tests.py      # Robusztuss√°gi tesztek
    ‚îî‚îÄ‚îÄ 07_explainability.py        # Magyar√°zhat√≥s√°g
```

## üîß Technol√≥giai Stack

### Core Technologies
- **Python 3.11+**: F≈ë programoz√°si nyelv
- **Docker**: Kont√©neriz√°ci√≥ √©s reproduk√°lhat√≥ k√∂rnyezet
- **CUDA 12.9 + cuDNN 9**: GPU t√°mogat√°s

### Machine Learning & Deep Learning
- **PyTorch 2.8.0**: Deep learning framework
- **Transformers 4.40.0**: Hugging Face transformer modellek
- **scikit-learn 1.5.2**: Baseline ML modellek
- **sentence-transformers 2.6.1**: Sentence embeddings

### Data Processing
- **pandas 2.3.3**: Adatkezel√©s
- **numpy 2.3.3**: Numerikus m≈±veletek
- **tqdm 4.66.5**: Progress bar-ok

### Visualization
- **matplotlib 3.10.7**: √Åbr√°k √©s vizualiz√°ci√≥k

## üéØ R√©szletes Pipeline Le√≠r√°s

### 1. Data Processing (01_data_processing.py)

**Bemenet:** JSON f√°jl(ok) az `/app/data` mapp√°ban

**Kimenet:** `train.csv`, `val.csv`, `test.csv` az `/app/output/processed/` mapp√°ban

**F≈ë funkci√≥k:**
- `load_json_data()`: Egyetlen JSON f√°jl bet√∂lt√©se
- `load_json_items()`: T√∂bb JSON f√°jl vagy mappa feldolgoz√°sa
- `clean_text()`: Unicode normaliz√°l√°s, whitespace tiszt√≠t√°s, speci√°lis karakterek kezel√©se
- `stratified_split()`: 60% train, 20% val, 20% test stratifik√°lt oszt√°s

**Adats√©ma:**
```json
{
  "data": { "text": "A sz√∂veg bekezd√©se..." },
  "annotations": [{
    "result": [{
      "value": { "choices": ["K√∂nnyen √©rthet≈ë"] }
    }]
  }]
}
```

**Adattiszt√≠t√°s:**
- NFC Unicode normaliz√°l√°s (magyar √©kezetek meg≈ërz√©se)
- T√∂bbsz√∂r√∂s whitespace elt√°vol√≠t√°sa
- Speci√°lis karakterek sz≈±r√©se, jogi √≠r√°sjelek megtart√°sa
- √úres sz√∂vegek √©s hi√°nyz√≥ labelek kisz≈±r√©se

### 2. Feature Engineering (02_feature_engineering.py)

**Bemenet:** Processed CSV-k

**Kimenet:** Kieg√©sz√≠tett CSV-k + vizualiz√°ci√≥k + opcion√°lis embeddings

**Sz√∂vegstatisztik√°k:**
- `word_count`: Szavak sz√°ma
- `avg_word_len`: √Åtlagos sz√≥hossz

**Opcion√°lis Embeddings:**
- Model: `paraphrase-multilingual-MiniLM-L12-v2`
- Form√°tum: NumPy t√∂mb√∂k (.npy)
- Metadata: JSON f√°jl az embeddings hely√©vel

**Vizualiz√°ci√≥k:**
- Word count hisztogram (train set)
- Average word length hisztogram (train set)

**K√∂rnyezeti v√°ltoz√≥k:**
- `ENABLE_EMBEDDINGS=true`: Embeddings gener√°l√°s bekapcsol√°sa
- `EMBEDDING_MODEL`: Sentence-BERT modell neve

### 3. Baseline Model (03_train_baseline.py)

**Architekt√∫ra:**
```
Text ‚Üí TF-IDF Vectorizer ‚Üí Logistic Regression ‚Üí Prediction
```

**TF-IDF konfigur√°ci√≥:**
- N-gram range: (1, 2) - unigram √©s bigram
- Max features: 20,000 (konfigur√°lhat√≥)
- Tokenization: alap√©rtelmezett
- Stopwords: nincs (jogi sz√∂veg specifikus szavak fontosak)

**Logistic Regression:**
- Multi-class: One-vs-Rest
- Max iterations: 1000
- Regularization: L2 (C=1.0, konfigur√°lhat√≥)
- Solver: lbfgs

**Kimenetek:**
- `baseline_model.pkl`: Sklearn Pipeline
- `baseline_val_report.json`: Valid√°ci√≥s metrik√°k
- `baseline_test_report.json`: Test metrik√°k
- `baseline_test_confusion_matrix.png`: Konf√∫zi√≥s m√°trix

**K√∂rnyezeti v√°ltoz√≥k:**
- `TFIDF_MAX_FEATURES=20000`: TF-IDF feature-√∂k maxim√°lis sz√°ma
- `TFIDF_NGRAM_MAX=2`: N-gram fels≈ë hat√°r
- `LR_C=1.0`: Regulariz√°ci√≥s param√©ter

### 4. Transformer Model (04_train_transformer.py)

**Alap√©rtelmezett modell:** `SZTAKI-HLT/hubert-base-cc` (magyar BERT)

**Architekt√∫ra:**
```
Text ‚Üí Tokenizer ‚Üí HuBERT Encoder ‚Üí Classification Head ‚Üí Softmax
```

**Tokeniz√°ci√≥:**
- Max length: 512 token
- Padding: max_length
- Truncation: True
- Special tokens: [CLS], [SEP]

**Fine-tuning strat√©gia:**
- Optimizer: AdamW
- Learning rate: 2e-5 (with warmup)
- Warmup: 10% of total steps
- Gradient clipping: 1.0
- Batch size: 8 (konfigur√°lhat√≥)
- Epochs: 3 (konfigur√°lhat√≥)

**Training loop:**
1. Forward pass
2. Loss calculation (Cross-Entropy)
3. Backward pass
4. Gradient clipping
5. Optimizer step
6. Scheduler step
7. Metrics logging

**Kimenetek:**
- `transformer_model/`: Teljes modell (config, weights, tokenizer)
- `label_mapping.json`: Label ‚Üí ID mapping
- `transformer_training_history.png`: Tan√≠t√°si g√∂rb√©k
- `transformer_test_report.json`: Test metrik√°k

**K√∂rnyezeti v√°ltoz√≥k:**
- `TRANSFORMER_MODEL`: Haszn√°land√≥ modell neve
- `BATCH_SIZE=8`: Batch m√©ret
- `EPOCHS=3`: Epochok sz√°ma
- `LEARNING_RATE=2e-5`: Tanul√°si r√°ta
- `MAX_LENGTH=512`: Max token hossz

**GPU k√∂vetelm√©nyek:**
- Minimum: 8GB VRAM (batch size 8-hoz)
- Aj√°nlott: 16GB+ VRAM (nagyobb batch size-hoz)

### 5. Evaluation (05_evaluation.py)

**Metrik√°k:**
- Accuracy (√∂sszes oszt√°lyra)
- Precision, Recall, F1-score (oszt√°lyonk√©nt)
- Support (p√©ld√°k sz√°ma oszt√°lyonk√©nt)
- Macro avg (egyenl≈ë s√∫lyoz√°s)
- Weighted avg (mintasz√°m szerinti s√∫lyoz√°s)

**Vizualiz√°ci√≥k:**
- Confusion matrix heatmap
- Per-class performance

**Kimenetek:**
- `baseline_test_report.json`: R√©szletes metrik√°k
- `baseline_test_confusion_matrix.png`: Konf√∫zi√≥s m√°trix

### 6. Robustness Tests (06_robustness_tests.py)

**Tesztelt perturb√°ci√≥k:**

1. **Karakter-szint≈± zaj:**
   - 5% zaj: V√©letlenszer≈± karakterm√≥dos√≠t√°s
   - 10% zaj: K√∂zepesen zajos sz√∂veg
   - 20% zaj: Er≈ësen zajos sz√∂veg

2. **Sz√∂veg csonkol√°s:**
   - 75%: Enyhe inform√°ci√≥veszt√©s
   - 50%: Fele hossz√∫s√°g
   - 25%: Csak az els≈ë negyed√©v

**Zaj m≈±veletek:**
- Delete: Karakter t√∂rl√©se
- Duplicate: Karakter duplik√°l√°sa
- Space: Karakter lecser√©l√©se space-re

**Kimenetek:**
- `robustness_results.json`: Minden teszt r√©szletes eredm√©nye
- `robustness_comparison.png`: Accuracy √∂sszehasonl√≠t√°s

**√ârt√©kel√©s:**
- Baseline accuracy (eredeti sz√∂veg)
- Degrad√°ci√≥ m√©r√©se (accuracy cs√∂kken√©s)
- Robusztuss√°g score

### 7. Explainability (07_explainability.py)

**Feature Importance:**
- Top 20 legfontosabb sz√≥/n-gram oszt√°lyonk√©nt
- Logistic Regression coefficients alapj√°n
- Pozit√≠v √©s negat√≠v s√∫lyok

**Prediction Explanations:**
- Top 10 test p√©lda
- True vs. Predicted label
- Top 3 predikci√≥ probability-vel
- Helyess√©g jel√∂l√©s

**Misclassification Analysis:**
- √ñsszes hib√°s predikci√≥
- Hibap√°rok gyakoris√°ga (true ‚Üí predicted)
- Top 10 legt√∂bb hibap√°r
- P√©lda hib√°s predikci√≥k

**Kimenetek:**
- `feature_importance.json`: Feature s√∫lyok
- `top_features_per_class.png`: Feature importance plot-ok
- `prediction_explanations.json`: Predikci√≥ magyar√°zatok
- `misclassification_analysis.json`: Hibaelemz√©s

## üê≥ Docker Konfigur√°ci√≥

### Base Image
```dockerfile
FROM pytorch/pytorch:2.8.0-cuda12.9-cudnn9-runtime
```

**El≈ëny√∂k:**
- PyTorch √©s CUDA el≈ëre telep√≠tve
- Optimaliz√°lt GPU haszn√°lat
- Kisebb image m√©ret (runtime vs. devel)

### Volume Mounting
```bash
-v "C:\...\data:/app/data"          # Input data
-v "C:\...\output:/app/output"      # Results
```

### GPU Access
```bash
--gpus all                           # Minden GPU el√©r√©se
```

### K√∂rnyezeti v√°ltoz√≥k √°tad√°sa
```bash
docker run -e EPOCHS=5 -e BATCH_SIZE=16 ...
```

## üìä Kimenet Strukt√∫ra

```
output/
‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îú‚îÄ‚îÄ train.csv               # Training set (60%)
‚îÇ   ‚îú‚îÄ‚îÄ val.csv                 # Validation set (20%)
‚îÇ   ‚îî‚îÄ‚îÄ test.csv                # Test set (20%)
‚îÇ
‚îú‚îÄ‚îÄ features/
‚îÇ   ‚îú‚îÄ‚îÄ train_word_count_hist.png
‚îÇ   ‚îú‚îÄ‚îÄ train_avg_word_len_hist.png
‚îÇ   ‚îú‚îÄ‚îÄ embeddings_train.npy    (opcion√°lis)
‚îÇ   ‚îú‚îÄ‚îÄ embeddings_val.npy      (opcion√°lis)
‚îÇ   ‚îú‚îÄ‚îÄ embeddings_test.npy     (opcion√°lis)
‚îÇ   ‚îî‚îÄ‚îÄ embeddings_meta.json    (opcion√°lis)
‚îÇ
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ baseline_model.pkl
‚îÇ   ‚îú‚îÄ‚îÄ label_mapping.json
‚îÇ   ‚îî‚îÄ‚îÄ transformer_model/
‚îÇ       ‚îú‚îÄ‚îÄ config.json
‚îÇ       ‚îú‚îÄ‚îÄ pytorch_model.bin
‚îÇ       ‚îî‚îÄ‚îÄ tokenizer files
‚îÇ
‚îú‚îÄ‚îÄ reports/
‚îÇ   ‚îú‚îÄ‚îÄ baseline_val_report.json
‚îÇ   ‚îú‚îÄ‚îÄ baseline_test_report.json
‚îÇ   ‚îú‚îÄ‚îÄ baseline_test_confusion_matrix.png
‚îÇ   ‚îú‚îÄ‚îÄ transformer_test_report.json
‚îÇ   ‚îî‚îÄ‚îÄ transformer_training_history.png
‚îÇ
‚îú‚îÄ‚îÄ evaluation/
‚îÇ   ‚îú‚îÄ‚îÄ baseline_test_report.json
‚îÇ   ‚îî‚îÄ‚îÄ baseline_test_confusion_matrix.png
‚îÇ
‚îú‚îÄ‚îÄ robustness/
‚îÇ   ‚îú‚îÄ‚îÄ robustness_results.json
‚îÇ   ‚îî‚îÄ‚îÄ robustness_comparison.png
‚îÇ
‚îî‚îÄ‚îÄ explainability/
    ‚îú‚îÄ‚îÄ feature_importance.json
    ‚îú‚îÄ‚îÄ top_features_per_class.png
    ‚îú‚îÄ‚îÄ prediction_explanations.json
    ‚îî‚îÄ‚îÄ misclassification_analysis.json
```

## üöÄ Futtat√°si √ötmutat√≥

### 1. Image Build
```powershell
docker build -t deeplearning_project-legal_text_decoder:1.0 .
```

### 2. Pipeline Futtat√°s
```powershell
docker run --rm --gpus all `
  -v "C:\path\to\data:/app/data" `
  -v "C:\path\to\output:/app/output" `
  deeplearning_project-legal_text_decoder:1.0 > training_log.txt 2>&1
```

### 3. Egyedi Konfigur√°ci√≥
```powershell
docker run --rm --gpus all `
  -e EPOCHS=5 `
  -e BATCH_SIZE=16 `
  -e ENABLE_EMBEDDINGS=true `
  -v "C:\path\to\data:/app/data" `
  -v "C:\path\to\output:/app/output" `
  deeplearning_project-legal_text_decoder:1.0
```

### 4. Csak Baseline (gyorsabb)
T√∂r√∂ld vagy nevezd √°t a `04_train_transformer.py` f√°jlt futtat√°s el≈ëtt.

## üîç Hibaelh√°r√≠t√°s

### GPU nem el√©rhet≈ë
**Probl√©ma:** `CUDA not available`

**Megold√°s:**
1. Ellen≈ërizd: `nvidia-smi` parancs m≈±k√∂dik-e
2. Docker Desktop GPU t√°mogat√°s bekapcsolva
3. NVIDIA Container Toolkit telep√≠tve

### Mem√≥ria t√∫lcsordul√°s (OOM)
**Probl√©ma:** `RuntimeError: CUDA out of memory`

**Megold√°s:**
- Cs√∂kkentsd a batch size-t: `-e BATCH_SIZE=4`
- Cs√∂kkentsd a max length-et: `-e MAX_LENGTH=256`
- Haszn√°lj kisebb modellt: `-e TRANSFORMER_MODEL=bert-base-multilingual-cased`

### Stratifik√°lt split hiba
**Probl√©ma:** `ValueError: The least populated class has only 1 member`

**Megold√°s:**
- T√∂bb adat sz√ºks√©ges
- Minimum 3-5 p√©lda oszt√°lyonk√©nt
- Ellen≈ërizd az adatokat: label eloszl√°s

### Lass√∫ fut√°s
**Probl√©ma:** Transformer tan√≠t√°s nagyon lass√∫

**Megold√°s:**
- GPU haszn√°lat ellen≈ërz√©se
- Kisebb epoch sz√°m: `-e EPOCHS=2`
- Csak baseline futtat√°sa (t√∂r√∂ld a 04-es scriptet)

## üìà Teljes√≠tm√©ny Benchmark-ok

### Baseline Model (TF-IDF + LogReg)
- **Training id≈ë:** ~2-5 perc (CPU)
- **Prediction id≈ë:** ~1 ms/document
- **Memory:** ~500 MB
- **Tipikus accuracy:** 60-75%

### Transformer Model (HuBERT)
- **Training id≈ë:** ~30-60 perc (GPU, 3 epoch)
- **Prediction id≈ë:** ~50 ms/document (GPU)
- **Memory:** ~2-4 GB (training), ~1 GB (inference)
- **Tipikus accuracy:** 70-85%

## üîê Biztons√°g √©s Adatv√©delem

- **Adatok:** Csak lok√°lis Docker volume-okban
- **Modellek:** Offline inference lehets√©ges
- **Nincsenek k√ºls≈ë API h√≠v√°sok** (embeddings kiv√©tel√©vel, ha be van kapcsolva)

## üìù Best Practices

1. **Version Control:** 
   - Commitolj minden v√°ltoztat√°st
   - Ne commitolj data/ √©s output/ mapp√°kat
   - Haszn√°ld a .gitignore-t

2. **Reproducibility:**
   - R√∂gz√≠tett random seed-ek a split-hez (42)
   - Docker image verzi√≥kezel√©s
   - Requirements.txt pontos verzi√≥sz√°mokkal

3. **Monitoring:**
   - training_log.txt folyamatos ellen≈ërz√©se
   - GPU utilization monitoring (nvidia-smi)
   - Disk space monitoring (modellek nagy m√©rete)

4. **Optimization:**
   - Mixed precision training (fp16) transformerhez
   - Gradient accumulation kis batch size-n√°l
   - Model distillation nagyobb modellekb≈ël

## üìö Tov√°bbi Forr√°sok

- [PyTorch dokument√°ci√≥](https://pytorch.org/docs/)
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/)
- [scikit-learn dokument√°ci√≥](https://scikit-learn.org/)
- [Docker dokument√°ci√≥](https://docs.docker.com/)

## ü§ù K√∂zrem≈±k√∂d√©s

A projekt a BME Deep Learning kurzus keret√©ben k√©sz√ºlt. Minden jav√≠t√°s √©s √∫j feature sz√≠vesen l√°tott!

---

**K√©sz√ºlt:** 2025. November  
**Verzi√≥:** 1.0  
**Licenc:** L√°sd LICENSE f√°jl
