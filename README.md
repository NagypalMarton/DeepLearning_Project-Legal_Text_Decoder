# Legal Text Decoder

NLP rendszer jogi szÃ¶vegek (ÃSZF/ÃFF) Ã©rthetÅ‘sÃ©gÃ©nek automatikus Ã©rtÃ©kelÃ©sÃ©re (1-5 skÃ¡la). Docker + PyTorch + GPU tÃ¡mogatÃ¡s.

## ğŸ“š TartalomjegyzÃ©k

- [Gyors IndÃ­tÃ¡s](#-gyors-indÃ­tÃ¡s)
- [KÃ¶vetelmÃ©ny-FÃ¡jl MegfeleltetÃ©s](#-kÃ¶vetelmÃ©ny-fÃ¡jl-megfeleltetÃ©s)
- [FÅ‘ lÃ©pÃ©sek (pipeline)](#-fÅ‘-lÃ©pÃ©sek-pipeline)
- [AdatformÃ¡tum](#-adatformÃ¡tum)
- [KÃ¶rnyezeti vÃ¡ltozÃ³k](#-kÃ¶rnyezeti-vÃ¡ltozÃ³k)
- [Kimenetek](#-kimenetek)
- [ML Service - API + GUI](#-ml-service---api--gui)
- [HibaelhÃ¡rÃ­tÃ¡s](#-hibaelhÃ¡rÃ­tÃ¡s)

## ğŸ¯ KÃ¶vetelmÃ©ny-FÃ¡jl MegfeleltetÃ©s

| # | Outstanding Level KÃ¶vetelmÃ©ny | ImplementÃ¡ciÃ³ | FÃ¡jl |
|---|-------------------------------|---------------|------|
| 1 | **Containerization** | Docker + GPU tÃ¡mogatÃ¡s | `Dockerfile` |
| 2 | **Data acquisition and analysis** | JSON parser, EDA, statistikÃ¡k | `01_data_acquisition_and_analysis.py` |
| 3 | **Data cleansing and preparation** | Text cleaning, stratified split | `02_data_cleansing_and_preparation.py` |
| 4 | **Defining evaluation criteria** | Metrics, confusion matrix | `05_defining_evaluation_criteria.py` |
| 5 | **Baseline model** | TF-IDF + LogisticRegression | `03_baseline_model.py` |
| 6 | **Incremental model development** | Transformer (HuBERT) fine-tuning | `04_incremental_model_development.py` |
| 7 | **Advanced evaluation** | Robustness + Explainability | `06_advanced_evaluation_robustness.py` <br> `07_advanced_evaluation_explainability.py` |
| 8 | **ML as a service** | REST API + Web GUI | `src/api/app.py` <br> `src/frontend/app.py` |

## ğŸ“‹ FÅ‘ lÃ©pÃ©sek (pipeline)

1. **01_data_acquisition_and_analysis.py** â€” JSON adatok betÃ¶ltÃ©se (fÃ¡jl vagy mappa), szÃ¶veg tisztÃ­tÃ¡s, label kinyerÃ©s, stratifikÃ¡lt train/val/test split Ã©s mentÃ©s CSV-be az OUTPUT_DIR/processed mappÃ¡ba.
2. **02_data_cleansing_and_preparation.py** â€” EgyszerÅ± szÃ¶vegstatisztikÃ¡k (word_count, avg_word_len) hozzÃ¡adÃ¡sa Ã©s opcionÃ¡lis Sentence-BERT beÃ¡gyazÃ¡sok mentÃ©se az OUTPUT_DIR/features mappÃ¡ba.
3. **03_baseline_model.py** â€” Baseline szÃ¶vegklasszifikÃ¡ciÃ³s modell: TFâ€‘IDF + LogisticRegression. Modell mentÃ©se (OUTPUT_DIR/models), metrikÃ¡k mentÃ©se (OUTPUT_DIR/reports).
4. **04_incremental_model_development.py** â€” Transformer alapÃº modell (pl. HuBERT) finomhangolÃ¡sa a jogi szÃ¶vegeken. GPU ajÃ¡nlott! Modell Ã©s tokenizer mentÃ©se (OUTPUT_DIR/models/transformer_model).
5. **05_defining_evaluation_criteria.py** â€” KÃ¼lÃ¶n Ã©rtÃ©kelÅ‘ script a baseline modellre a test spliten (OUTPUT_DIR/evaluation).
6. **06_advanced_evaluation_robustness.py** â€” RobusztussÃ¡gi tesztek: zajjal Ã©s csonkolÃ¡ssal mÃ³dosÃ­tott szÃ¶vegeken Ã©rtÃ©keli a baseline modellt (OUTPUT_DIR/robustness).
7. **07_advanced_evaluation_explainability.py** â€” Modell Ã©rtelmezhetÅ‘sÃ©g: top feature-Ã¶k osztÃ¡lyonkÃ©nt, predikciÃ³ magyarÃ¡zatok, hibaelemzÃ©s (OUTPUT_DIR/explainability).

> A `src/run.sh` sorban futtatja az Ã¶sszes `src/*.py` fÃ¡jlt (Ã¡bÃ©cÃ©rendben). Dockerben ez az alapÃ©rtelmezett belÃ©pÃ©si pont.

## AdatformÃ¡tum (JSON)

ElvÃ¡rt minimÃ¡lis sÃ©ma egy elemre:

```json
{
	"data": { "text": "A bekezdÃ©s szÃ¶vegeâ€¦" },
	"annotations": [
		{
			"result": [
				{ "value": { "choices": ["KÃ¶nnyen Ã©rthetÅ‘"] } }
			]
		}
	]
}
```

Fontos: ha tÃ¶bb annotÃ¡ciÃ³/eredmÃ©ny van, jelenleg az elsÅ‘ elem elsÅ‘ vÃ¡lasztÃ¡sa kerÃ¼l felhasznÃ¡lÃ¡sra.

## KÃ¶rnyezeti vÃ¡ltozÃ³k

**AdatkezelÃ©s:**
- `DATA_DIR` â€” Bemeneti adat mappa (alap: `/app/data` Dockerben).
- `OUTPUT_DIR` â€” Kimeneti mappa (alap: `/app/output`).

**Baseline modell (TF-IDF + LogisticRegression):**
- `TFIDF_MAX_FEATURES` â€” TFâ€‘IDF max jellemzÅ‘k szÃ¡ma (alap: 20000).
- `TFIDF_NGRAM_MAX` â€” TFâ€‘IDF n-gram felsÅ‘ hatÃ¡r (alap: 2).
- `LR_C` â€” LogisticRegression C paramÃ©tere (alap: 1.0).

**Transformer modell:**
- `TRANSFORMER_MODEL` â€” HasznÃ¡landÃ³ transformer modell neve (alap: `SZTAKI-HLT/hubert-base-cc`).
- `BATCH_SIZE` â€” Batch mÃ©ret a tanÃ­tÃ¡shoz (alap: 8).
- `EPOCHS` â€” TanÃ­tÃ¡si epochok szÃ¡ma (alap: 3).
- `LEARNING_RATE` â€” TanulÃ¡si rÃ¡ta (alap: 2e-5).
- `MAX_LENGTH` â€” MaximÃ¡lis szekvencia hossz tokenizÃ¡lÃ¡skor (alap: 512).

**Feature engineering:**
- `ENABLE_EMBEDDINGS` â€” Ha `true`, Sentenceâ€‘BERT beÃ¡gyazÃ¡sok szÃ¡mÃ­tÃ¡sa a 02-es lÃ©pÃ©sben (alap: false).
- `EMBEDDING_MODEL` â€” Embedding modell neve (alap: `paraphrase-multilingual-MiniLM-L12-v2`).

## FuttatÃ¡s Dockerrel

1) Image build:

```powershell
docker build -t deeplearning_project-legal_text_decoder:1.0 .
```

2) KontÃ©ner futtatÃ¡sa (PowerShell, GPU-val Ã©s volumekkel):

```powershell
docker run --rm --gpus all `
	-v "C:\Users\nagyp\.vscode\DeepLearning Project\attach_folders\data:/app/data" `
	-v "C:\Users\nagyp\.vscode\DeepLearning Project\attach_folders\output:/app/output" `
	deeplearning_project-legal_text_decoder:1.0 > training_log.txt 2>&1
```

Az Ã¶sszes kimenet az `C:\Users\nagyp\.vscode\DeepLearning Project\attach_folders\output` mappÃ¡ban lesz elÃ©rhetÅ‘ (Windows host oldalon).

## LokÃ¡lis futtatÃ¡s (opcionÃ¡lis)

Python kÃ¶rnyezetben (a `requirements.txt` telepÃ­tÃ©se utÃ¡n) egyenkÃ©nt is futtathatÃ³k a scriptek:

```powershell
$env:DATA_DIR = "C:\\path\\to\\data"; $env:OUTPUT_DIR = "C:\\path\\to\\output"; python src/01_data_acquisition_and_analysis.py
python src/02_data_cleansing_and_preparation.py
python src/03_baseline_model.py
python src/05_defining_evaluation_criteria.py
```

## Kimenetek

- `OUTPUT_DIR/processed/` â€” `train.csv`, `val.csv`, `test.csv` (vagy `processed_data.csv` fallback esetÃ©n) szÃ¶vegstatisztikÃ¡kkal kiegÃ©szÃ­tve
- `OUTPUT_DIR/features/` â€” szÃ¶vegstatisztika Ã¡brÃ¡k (hisztogramok), opcionÃ¡lis `embeddings_*.npy` Ã©s `embeddings_meta.json`
- `OUTPUT_DIR/models/` â€” `baseline_model.pkl` (TF-IDF + LogReg), `transformer_model/` (finomhangolt transformer), `label_mapping.json`
- `OUTPUT_DIR/reports/` â€” baseline Ã©s transformer metrikÃ¡k (val/test JSON riportok), `transformer_training_history.png`
- `OUTPUT_DIR/evaluation/` â€” kÃ¼lÃ¶n teszt riport Ã©s konfÃºziÃ³s mÃ¡trix a baseline modellhez
- `OUTPUT_DIR/robustness/` â€” robusztussÃ¡gi tesztek eredmÃ©nyei (`robustness_results.json`, `robustness_comparison.png`)
- `OUTPUT_DIR/explainability/` â€” feature importance, predikciÃ³ magyarÃ¡zatok, hibaelemzÃ©s JSON-ben Ã©s Ã¡brÃ¡kban

## MegjegyzÃ©sek Ã©s ismert korlÃ¡tok

- A stratifikÃ¡lt split legalÃ¡bb kÃ©t osztÃ¡lyt Ã©s elegendÅ‘ mintÃ¡t igÃ©nyel osztÃ¡lyonkÃ©nt. KevÃ©s minta esetÃ©n hibaÃ¼zenetet kaphatsz.
- A Sentenceâ€‘BERT beÃ¡gyazÃ¡sok letÃ¶ltÃ©se internetet Ã©s tÃ¶bb memÃ³riÃ¡t igÃ©nyelhet; alapÃ©rtelmezetten ki van kapcsolva.
- A **transformer modell tanÃ­tÃ¡sa (04_incremental_model_development.py) GPU-t igÃ©nyel** a hatÃ©kony futÃ¡shoz. CPU-n is fut, de sokkal lassabb.
- A transformer modell alapÃ©rtelmezetten a magyar **HuBERT** modellt hasznÃ¡lja, de ez kÃ¶rnyezeti vÃ¡ltozÃ³val mÃ³dosÃ­thatÃ³ mÃ¡s modellekre (pl. `bert-base-multilingual-cased`).
- Ha csak a baseline modellt szeretnÃ©d futtatni (gyorsabb, kevesebb erÅ‘forrÃ¡s), egyszerÅ±en tÃ¶rÃ¶ld vagy nevezd Ã¡t a `04_incremental_model_development.py` fÃ¡jlt a pipeline elÅ‘tt.

## ğŸš€ Gyors IndÃ­tÃ¡s

```powershell
# 1. Build
docker build -t deeplearning_project-legal_text_decoder:1.0 .

# 2. FuttatÃ¡s (GPU-val)
docker run --rm --gpus all `
  -v "C:\path\to\data:/app/data" `
  -v "C:\path\to\output:/app/output" `
  deeplearning_project-legal_text_decoder:1.0 > training_log.txt 2>&1
```

**FutÃ¡si idÅ‘:** ~45-60 perc GPU-val | ~6+ Ã³ra CPU-n (transformer miatt)

**Fontos:** 
- A `data/` kÃ¶nyvtÃ¡r tartalmazza a bemeneti JSON adatokat (host gÃ©pen)
- Az `output/` kÃ¶nyvtÃ¡r a futÃ¡s eredmÃ©nyeit tartalmazza (betanÃ­tott modellek, kÃ©pek, riportok)
- Ezek volume-kÃ©nt csatolÃ³dnak a kontÃ©nerbe (`/app/data` Ã©s `/app/output`)
- A Python scriptek a kontÃ©neren belÃ¼l az `/app/output` mappÃ¡ba mentik az eredmÃ©nyeket
- A `data/` Ã©s `output/` kÃ¶nyvtÃ¡rak **NEM** kerÃ¼lnek Git verziÃ³kezelÃ©s alÃ¡ (`.gitignore`)

## ğŸ“‹ FÅ‘ lÃ©pÃ©sek (pipeline)

1. **01_data_acquisition_and_analysis.py** â€” JSON adatok betÃ¶ltÃ©se (fÃ¡jl vagy mappa), szÃ¶veg tisztÃ­tÃ¡s, label kinyerÃ©s, stratifikÃ¡lt train/val/test split (60/20/20) Ã©s mentÃ©s CSV-be az OUTPUT_DIR/processed mappÃ¡ba.
2. **02_data_cleansing_and_preparation.py** â€” EgyszerÅ± szÃ¶vegstatisztikÃ¡k (word_count, avg_word_len) hozzÃ¡adÃ¡sa Ã©s opcionÃ¡lis Sentence-BERT beÃ¡gyazÃ¡sok mentÃ©se az OUTPUT_DIR/features mappÃ¡ba.
3. **03_baseline_model.py** â€” Baseline szÃ¶vegklasszifikÃ¡ciÃ³s modell: TFâ€‘IDF + LogisticRegression. Modell mentÃ©se (OUTPUT_DIR/models), metrikÃ¡k mentÃ©se (OUTPUT_DIR/reports).
4. **04_incremental_model_development.py** â€” Transformer alapÃº modell (pl. HuBERT) finomhangolÃ¡sa a jogi szÃ¶vegeken. GPU ajÃ¡nlott! Modell Ã©s tokenizer mentÃ©se (OUTPUT_DIR/models/transformer_model).
5. **05_defining_evaluation_criteria.py** â€” KÃ¼lÃ¶n Ã©rtÃ©kelÅ‘ script a baseline modellre a test spliten (OUTPUT_DIR/evaluation).
6. **06_advanced_evaluation_robustness.py** â€” RobusztussÃ¡gi tesztek: zajjal Ã©s csonkolÃ¡ssal mÃ³dosÃ­tott szÃ¶vegeken Ã©rtÃ©keli a baseline modellt (OUTPUT_DIR/robustness).
7. **07_advanced_evaluation_explainability.py** â€” Modell Ã©rtelmezhetÅ‘sÃ©g: top feature-Ã¶k osztÃ¡lyonkÃ©nt, predikciÃ³ magyarÃ¡zatok, hibaelemzÃ©s (OUTPUT_DIR/explainability).

> A `src/run.sh` sorban futtatja az Ã¶sszes script-et a megadott sorrendben. Dockerben ez az alapÃ©rtelmezett belÃ©pÃ©si pont.

## ğŸ“„ AdatformÃ¡tum

ElvÃ¡rt minimÃ¡lis sÃ©ma egy elemre:

```json
{
	"data": { "text": "A bekezdÃ©s szÃ¶vegeâ€¦" },
	"annotations": [
		{
			"result": [
				{ "value": { "choices": ["KÃ¶nnyen Ã©rthetÅ‘"] } }
			]
		}
	]
}
```

**MegjegyzÃ©s:** Az elsÅ‘ elem elsÅ‘ vÃ¡lasztÃ¡sa kerÃ¼l felhasznÃ¡lÃ¡sra: `annotations[0].result[0].value.choices[0]`

## ğŸ“ Projekt StruktÃºra

```
DeepLearning_Project-Legal_Text_Decoder/
â”œâ”€â”€ Dockerfile                                    # Containerization
â”œâ”€â”€ docker-compose.yml                            # ML Service orchestration
â”œâ”€â”€ requirements.txt                              # Python fÃ¼ggÅ‘sÃ©gek
â”œâ”€â”€ README.md                                     # DokumentÃ¡ciÃ³
â”œâ”€â”€ .gitignore                                    # Git kizÃ¡rÃ¡sok
â”‚
â”œâ”€â”€ data/                                         # INPUT (volume mount)
â”‚   â””â”€â”€ *.json                                    # Jogi szÃ¶veg adatok
â”‚
â”œâ”€â”€ src/                                          # PYTHON SCRIPTEK
â”‚   â”œâ”€â”€ run.sh                                    # Pipeline orchestrator
â”‚   â”œâ”€â”€ run_service.sh                            # Service launcher (Bash)
â”‚   â”œâ”€â”€ run_service.ps1                           # Service launcher (PowerShell)
â”‚   â”‚
â”‚   â”œâ”€â”€ 01_data_acquisition_and_analysis.py       # KÃ¶vetelmÃ©ny #2
â”‚   â”œâ”€â”€ 02_data_cleansing_and_preparation.py      # KÃ¶vetelmÃ©ny #3
â”‚   â”œâ”€â”€ 03_baseline_model.py                      # KÃ¶vetelmÃ©ny #5
â”‚   â”œâ”€â”€ 04_incremental_model_development.py       # KÃ¶vetelmÃ©ny #6
â”‚   â”œâ”€â”€ 05_defining_evaluation_criteria.py        # KÃ¶vetelmÃ©ny #4
â”‚   â”œâ”€â”€ 06_advanced_evaluation_robustness.py      # KÃ¶vetelmÃ©ny #7a
â”‚   â”œâ”€â”€ 07_advanced_evaluation_explainability.py  # KÃ¶vetelmÃ©ny #7b
â”‚   â”‚
â”‚   â”œâ”€â”€ api/                                      # REST API Backend
â”‚   â”‚   â””â”€â”€ app.py                                # KÃ¶vetelmÃ©ny #8a
â”‚   â”‚
â”‚   â””â”€â”€ frontend/                                 # Web GUI
â”‚       â””â”€â”€ app.py                                # KÃ¶vetelmÃ©ny #8b
â”‚
â””â”€â”€ output/                                       # OUTPUT (volume mount)
    â”œâ”€â”€ processed/
    â”‚   â”œâ”€â”€ train.csv               # Training set (60%, szÃ¶vegstatisztikÃ¡kkal)
    â”‚   â”œâ”€â”€ val.csv                 # Validation set (20%)
    â”‚   â””â”€â”€ test.csv                # Test set (20%)
    â”‚
    â”œâ”€â”€ features/
    â”‚   â”œâ”€â”€ train_word_count_hist.png
    â”‚   â”œâ”€â”€ train_avg_word_len_hist.png
    â”‚   â”œâ”€â”€ embeddings_train.npy    (ha ENABLE_EMBEDDINGS=true)
    â”‚   â”œâ”€â”€ embeddings_val.npy
    â”‚   â”œâ”€â”€ embeddings_test.npy
    â”‚   â””â”€â”€ embeddings_meta.json
    â”‚
    â”œâ”€â”€ models/
    â”‚   â”œâ”€â”€ baseline_model.pkl      # Sklearn pipeline
    â”‚   â”œâ”€â”€ label_mapping.json      # Label â†’ ID mapping
    â”‚   â””â”€â”€ transformer_model/      # HuBERT modell
    â”‚       â”œâ”€â”€ config.json
    â”‚       â”œâ”€â”€ pytorch_model.bin
    â”‚       â””â”€â”€ tokenizer files
    â”‚
    â”œâ”€â”€ reports/
    â”‚   â”œâ”€â”€ baseline_val_report.json
    â”‚   â”œâ”€â”€ baseline_test_report.json
    â”‚   â”œâ”€â”€ baseline_test_confusion_matrix.png
    â”‚   â”œâ”€â”€ transformer_test_report.json
    â”‚   â””â”€â”€ transformer_training_history.png
    â”‚
    â”œâ”€â”€ evaluation/
    â”‚   â”œâ”€â”€ baseline_test_report.json
    â”‚   â””â”€â”€ baseline_test_confusion_matrix.png
    â”‚
    â”œâ”€â”€ robustness/
    â”‚   â”œâ”€â”€ robustness_results.json
    â”‚   â””â”€â”€ robustness_comparison.png
    â”‚
    â””â”€â”€ explainability/
        â”œâ”€â”€ feature_importance.json
        â”œâ”€â”€ top_features_per_class.png
        â”œâ”€â”€ prediction_explanations.json
        â””â”€â”€ misclassification_analysis.json
```

## âš™ï¸ KÃ¶rnyezeti vÃ¡ltozÃ³k

### AlapvetÅ‘
| VÃ¡ltozÃ³ | AlapÃ©rtelmezett | LeÃ­rÃ¡s |
|---------|----------------|--------|
| `DATA_DIR` | `/app/data` | Input adatok helye |
| `OUTPUT_DIR` | `/app/output` | Kimenetek helye |

### Baseline
| VÃ¡ltozÃ³ | AlapÃ©rtelmezett | LeÃ­rÃ¡s |
|---------|----------------|--------|
| `TFIDF_MAX_FEATURES` | `20000` | Max TF-IDF feature-Ã¶k szÃ¡ma |
| `TFIDF_NGRAM_MAX` | `2` | N-gram felsÅ‘ hatÃ¡r |
| `LR_C` | `1.0` | RegularizÃ¡ciÃ³s paramÃ©ter |

### Transformer
| VÃ¡ltozÃ³ | AlapÃ©rtelmezett | LeÃ­rÃ¡s |
|---------|----------------|--------|
| `TRANSFORMER_MODEL` | `SZTAKI-HLT/hubert-base-cc` | Transformer modell nÃ©v |
| `BATCH_SIZE` | `8` | Batch mÃ©ret (8GB VRAM-hoz) |
| `EPOCHS` | `3` | Epochok szÃ¡ma |
| `LEARNING_RATE` | `2e-5` | TanulÃ¡si rÃ¡ta |
| `MAX_LENGTH` | `512` | Max token hossz |

### Embeddings
| VÃ¡ltozÃ³ | AlapÃ©rtelmezett | LeÃ­rÃ¡s |
|---------|----------------|--------|
| `ENABLE_EMBEDDINGS` | `false` | Sentence-BERT embeddings be/ki |
| `EMBEDDING_MODEL` | `paraphrase-multilingual-MiniLM-L12-v2` | Embedding modell |

## ï¿½ Kimenetek

```
output/
â”œâ”€â”€ processed/          # train/val/test CSV-k
â”œâ”€â”€ features/           # StatisztikÃ¡k, embeddings
â”œâ”€â”€ models/             # baseline_model.pkl, transformer_model/
â”œâ”€â”€ reports/            # MetrikÃ¡k, confusion matrix
â”œâ”€â”€ evaluation/         # Test eredmÃ©nyek
â”œâ”€â”€ robustness/         # RobusztussÃ¡gi tesztek
â””â”€â”€ explainability/     # Feature importance
```

## ğŸŒ ML Service - API + GUI

**FONTOS:** Ez a szolgÃ¡ltatÃ¡s **KÃœLÃ–N** fut a training pipeline-tÃ³l! ElÅ‘szÃ¶r futtasd le a training pipeline-t, majd utÃ¡na indÃ­tsd el a service-t.

### MiÃ©rt kÃ¼lÃ¶n?

A projekt kiÃ©rtÃ©kelÃ©se az eredeti pipeline futtatÃ¡sÃ¡val tÃ¶rtÃ©nik (lÃ¡sd fent). Az ML service egy **opcionÃ¡lis bÃ³nusz funkciÃ³**, amely lehetÅ‘vÃ© teszi a betanÃ­tott modellek hasznÃ¡latÃ¡t egy webes felÃ¼leten.

### API Backend (FastAPI)

**REST API** a betanÃ­tott modellek kiszolgÃ¡lÃ¡sÃ¡ra:

```bash
# LokÃ¡lisan (Python kÃ¶rnyezetben)
python src/api/app.py

# Docker-rel
docker run -d -p 8000:8000 \
  -v "C:\path\to\output:/app/output:ro" \
  deeplearning_project-legal_text_decoder:1.0 \
  python src/api/app.py
```

**Endpoints:**
- `GET /` - Health check
- `POST /predict` - PredikciÃ³ (JSON: `{"text": "...", "model_type": "baseline"}`)
- `GET /models` - ElÃ©rhetÅ‘ modellek listÃ¡ja
- `GET /docs` - Swagger API dokumentÃ¡ciÃ³

### GUI Frontend (Streamlit)

**Webes felÃ¼let** a modellek interaktÃ­v tesztelÃ©sÃ©hez:

```bash
# LokÃ¡lisan
streamlit run src/frontend/app.py

# Docker Compose (ajÃ¡nlott, API + Frontend egyÃ¼tt)
docker-compose up
```

**ElÃ©rhetÅ‘:** http://localhost:8501

### Gyors indÃ­tÃ¡s scriptek

```powershell
# PowerShell
.\src\run_service.ps1

# Vagy Linux/macOS
bash src/run_service.sh
```

### Docker Compose (legegyszerÅ±bb)

```powershell
# IndÃ­tÃ¡s
docker-compose up -d

# LeÃ¡llÃ­tÃ¡s
docker-compose down
```

**ElÃ©rÃ©s:**
- Frontend: http://localhost:8501
- API Docs: http://localhost:8000/docs

### FunkciÃ³k

âœ… **KÃ©t modell** - Baseline Ã©s Transformer kÃ¶zÃ¶tti vÃ¡ltÃ¡s  
âœ… **ValÃ³s idejÅ± predikciÃ³** - Azonnali Ã©rtÃ©kelÃ©s  
âœ… **VizualizÃ¡ciÃ³k** - ValÃ³szÃ­nÅ±sÃ©g eloszlÃ¡s grafikonok  
âœ… **PÃ©lda szÃ¶vegek** - Gyors tesztelÃ©shez  
âœ… **REST API** - KÃ¼lsÅ‘ alkalmazÃ¡sokbÃ³l is hasznÃ¡lhatÃ³  

---

## ğŸ› HibaelhÃ¡rÃ­tÃ¡s

| ProblÃ©ma | MegoldÃ¡s |
|----------|----------|
| `CUDA not available` | EllenÅ‘rizd: `nvidia-smi`, Docker GPU support |
| `CUDA out of memory` | `-e BATCH_SIZE=4` vagy `-e MAX_LENGTH=256` |
| Stratified split hiba | Min. 3-5 pÃ©lda/osztÃ¡ly szÃ¼ksÃ©ges |
| LassÃº futÃ¡s CPU-n | HasznÃ¡lj GPU-t vagy tÃ¶rÃ¶ld `04_incremental_model_development.py` |
| JSON parsing hiba | EllenÅ‘rizd az AdatformÃ¡tum szekciÃ³t |

## â±ï¸ TeljesÃ­tmÃ©ny

| Modell | Accuracy | Training | GPU | Memory |
|--------|----------|----------|-----|--------|
| Baseline | 60-75% | ~3 min | Nem kell | ~500 MB |
| Transformer | 70-85% | ~40 min | 8GB+ VRAM | ~2-4 GB |

**Teljes pipeline:** ~45-60 min (GPU) | ~6+ Ã³ra (CPU)

## ğŸ“ Licenc

LÃ¡sd: `LICENSE`
