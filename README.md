# Legal Text Decoder

NLP rendszer jogi szÃ¶vegek (ÃSZF/ÃFF) Ã©rthetÅ‘sÃ©gÃ©nek automatikus Ã©rtÃ©kelÃ©sÃ©re (1-5 skÃ¡la). Docker + PyTorch + GPU tÃ¡mogatÃ¡s.

## ğŸ“š TartalomjegyzÃ©k

- [Gyors IndÃ­tÃ¡s](#-gyors-indÃ­tÃ¡s)
- [FÅ‘ lÃ©pÃ©sek (pipeline)](#-fÅ‘-lÃ©pÃ©sek-pipeline)
- [AdatformÃ¡tum](#-adatformÃ¡tum)
- [KÃ¶rnyezeti vÃ¡ltozÃ³k](#-kÃ¶rnyezeti-vÃ¡ltozÃ³k)
- [Kimenetek](#-kimenetek)
- [HibaelhÃ¡rÃ­tÃ¡s](#-hibaelhÃ¡rÃ­tÃ¡s)

## FÅ‘ lÃ©pÃ©sek (pipeline)

1. **01_data_processing.py** â€” JSON adatok betÃ¶ltÃ©se (fÃ¡jl vagy mappa), szÃ¶veg tisztÃ­tÃ¡s, label kinyerÃ©s, stratifikÃ¡lt train/val/test split Ã©s mentÃ©s CSV-be az OUTPUT_DIR/processed mappÃ¡ba.
2. **02_feature_engineering.py** â€” EgyszerÅ± szÃ¶vegstatisztikÃ¡k (word_count, avg_word_len) hozzÃ¡adÃ¡sa Ã©s opcionÃ¡lis Sentence-BERT beÃ¡gyazÃ¡sok mentÃ©se az OUTPUT_DIR/features mappÃ¡ba.
3. **03_train_baseline.py** â€” Baseline szÃ¶vegklasszifikÃ¡ciÃ³s modell: TFâ€‘IDF + LogisticRegression. Modell mentÃ©se (OUTPUT_DIR/models), metrikÃ¡k mentÃ©se (OUTPUT_DIR/reports).
4. **04_train_transformer.py** â€” Transformer alapÃº modell (pl. HuBERT) finomhangolÃ¡sa a jogi szÃ¶vegeken. GPU ajÃ¡nlott! Modell Ã©s tokenizer mentÃ©se (OUTPUT_DIR/models/transformer_model).
5. **05_evaluation.py** â€” KÃ¼lÃ¶n Ã©rtÃ©kelÅ‘ script a baseline modellre a test spliten (OUTPUT_DIR/evaluation).
6. **06_robustness_tests.py** â€” RobusztussÃ¡gi tesztek: zajjal Ã©s csonkolÃ¡ssal mÃ³dosÃ­tott szÃ¶vegeken Ã©rtÃ©keli a baseline modellt (OUTPUT_DIR/robustness).
7. **07_explainability.py** â€” Modell Ã©rtelmezhetÅ‘sÃ©g: top feature-Ã¶k osztÃ¡lyonkÃ©nt, predikciÃ³ magyarÃ¡zatok, hibaelemzÃ©s (OUTPUT_DIR/explainability).

> A `src/run.sh` sorban futtatja az Ã¶sszes `src/*.py` fÃ¡jlt (Ã¡bÃ©cÃ©rendben). Dockerben ez az alapÃ©rtelmezett belÃ©pÃ©si pont.

## AdatformÃ¡tum (JSON)

ElvÃ¡rt minimÃ¡lis sÃ©ma egy elemre:

```json
{
	"data": { "text": "A bekezdÃ©s szÃ¶vegeâ€¦" },
	"annotations": [
		{
			"result": [
				{ "value": { "choices": ["KÃ¶nnyen Ã©rthetÅ‘"] } }
			]
		}
	]
}
```

Fontos: ha tÃ¶bb annotÃ¡ciÃ³/eredmÃ©ny van, jelenleg az elsÅ‘ elem elsÅ‘ vÃ¡lasztÃ¡sa kerÃ¼l felhasznÃ¡lÃ¡sra.

## KÃ¶rnyezeti vÃ¡ltozÃ³k

**AdatkezelÃ©s:**
- `DATA_DIR` â€” Bemeneti adat mappa (alap: `/app/data` Dockerben).
- `OUTPUT_DIR` â€” Kimeneti mappa (alap: `/app/output`).

**Baseline modell (TF-IDF + LogisticRegression):**
- `TFIDF_MAX_FEATURES` â€” TFâ€‘IDF max jellemzÅ‘k szÃ¡ma (alap: 20000).
- `TFIDF_NGRAM_MAX` â€” TFâ€‘IDF n-gram felsÅ‘ hatÃ¡r (alap: 2).
- `LR_C` â€” LogisticRegression C paramÃ©tere (alap: 1.0).

**Transformer modell:**
- `TRANSFORMER_MODEL` â€” HasznÃ¡landÃ³ transformer modell neve (alap: `SZTAKI-HLT/hubert-base-cc`).
- `BATCH_SIZE` â€” Batch mÃ©ret a tanÃ­tÃ¡shoz (alap: 8).
- `EPOCHS` â€” TanÃ­tÃ¡si epochok szÃ¡ma (alap: 3).
- `LEARNING_RATE` â€” TanulÃ¡si rÃ¡ta (alap: 2e-5).
- `MAX_LENGTH` â€” MaximÃ¡lis szekvencia hossz tokenizÃ¡lÃ¡skor (alap: 512).

**Feature engineering:**
- `ENABLE_EMBEDDINGS` â€” Ha `true`, Sentenceâ€‘BERT beÃ¡gyazÃ¡sok szÃ¡mÃ­tÃ¡sa a 02-es lÃ©pÃ©sben (alap: false).
- `EMBEDDING_MODEL` â€” Embedding modell neve (alap: `paraphrase-multilingual-MiniLM-L12-v2`).

## FuttatÃ¡s Dockerrel

1) Image build:

```powershell
docker build -t deeplearning_project-legal_text_decoder:1.0 .
```

2) KontÃ©ner futtatÃ¡sa (PowerShell, GPU-val Ã©s volumekkel):

```powershell
docker run --rm --gpus all `
	-v "C:\Users\nagyp\.vscode\DeepLearning Project\attach_folders\data:/app/data" `
	-v "C:\Users\nagyp\.vscode\DeepLearning Project\attach_folders\output:/app/output" `
	deeplearning_project-legal_text_decoder:1.0 > training_log.txt 2>&1
```

Az Ã¶sszes kimenet az `C:\Users\nagyp\.vscode\DeepLearning Project\attach_folders\output` mappÃ¡ban lesz elÃ©rhetÅ‘ (Windows host oldalon).

## LokÃ¡lis futtatÃ¡s (opcionÃ¡lis)

Python kÃ¶rnyezetben (a `requirements.txt` telepÃ­tÃ©se utÃ¡n) egyenkÃ©nt is futtathatÃ³k a scriptek:

```powershell
$env:DATA_DIR = "C:\\path\\to\\data"; $env:OUTPUT_DIR = "C:\\path\\to\\output"; python src/01_data_processing.py
python src/02_feature_engineering.py
python src/03_train_baseline.py
python src/05_evaluation.py
```

## Kimenetek

- `OUTPUT_DIR/processed/` â€” `train.csv`, `val.csv`, `test.csv` (vagy `processed_data.csv` fallback esetÃ©n) szÃ¶vegstatisztikÃ¡kkal kiegÃ©szÃ­tve
- `OUTPUT_DIR/features/` â€” szÃ¶vegstatisztika Ã¡brÃ¡k (hisztogramok), opcionÃ¡lis `embeddings_*.npy` Ã©s `embeddings_meta.json`
- `OUTPUT_DIR/models/` â€” `baseline_model.pkl` (TF-IDF + LogReg), `transformer_model/` (finomhangolt transformer), `label_mapping.json`
- `OUTPUT_DIR/reports/` â€” baseline Ã©s transformer metrikÃ¡k (val/test JSON riportok), `transformer_training_history.png`
- `OUTPUT_DIR/evaluation/` â€” kÃ¼lÃ¶n teszt riport Ã©s konfÃºziÃ³s mÃ¡trix a baseline modellhez
- `OUTPUT_DIR/robustness/` â€” robusztussÃ¡gi tesztek eredmÃ©nyei (`robustness_results.json`, `robustness_comparison.png`)
- `OUTPUT_DIR/explainability/` â€” feature importance, predikciÃ³ magyarÃ¡zatok, hibaelemzÃ©s JSON-ben Ã©s Ã¡brÃ¡kban

## MegjegyzÃ©sek Ã©s ismert korlÃ¡tok

- A stratifikÃ¡lt split legalÃ¡bb kÃ©t osztÃ¡lyt Ã©s elegendÅ‘ mintÃ¡t igÃ©nyel osztÃ¡lyonkÃ©nt. KevÃ©s minta esetÃ©n hibaÃ¼zenetet kaphatsz.
- A Sentenceâ€‘BERT beÃ¡gyazÃ¡sok letÃ¶ltÃ©se internetet Ã©s tÃ¶bb memÃ³riÃ¡t igÃ©nyelhet; alapÃ©rtelmezetten ki van kapcsolva.
- A **transformer modell tanÃ­tÃ¡sa (04_train_transformer.py) GPU-t igÃ©nyel** a hatÃ©kony futÃ¡shoz. CPU-n is fut, de sokkal lassabb.
- A transformer modell alapÃ©rtelmezetten a magyar **HuBERT** modellt hasznÃ¡lja, de ez kÃ¶rnyezeti vÃ¡ltozÃ³val mÃ³dosÃ­thatÃ³ mÃ¡s modellekre (pl. `bert-base-multilingual-cased`).
- Ha csak a baseline modellt szeretnÃ©d futtatni (gyorsabb, kevesebb erÅ‘forrÃ¡s), egyszerÅ±en tÃ¶rÃ¶ld vagy nevezd Ã¡t a `04_train_transformer.py` fÃ¡jlt a pipeline elÅ‘tt.

## ğŸš€ Gyors IndÃ­tÃ¡s

```powershell
# 1. Build
docker build -t deeplearning_project-legal_text_decoder:1.0 .

# 2. FuttatÃ¡s (GPU-val)
docker run --rm --gpus all `
  -v "C:\path\to\data:/app/data" `
  -v "C:\path\to\output:/app/output" `
  deeplearning_project-legal_text_decoder:1.0 > training_log.txt 2>&1
```

**FutÃ¡si idÅ‘:** ~45-60 perc GPU-val | ~6+ Ã³ra CPU-n (transformer miatt)

## ğŸ“‹ FÅ‘ lÃ©pÃ©sek (pipeline)

1. **01_data_processing.py** â€” JSON adatok betÃ¶ltÃ©se (fÃ¡jl vagy mappa), szÃ¶veg tisztÃ­tÃ¡s, label kinyerÃ©s, stratifikÃ¡lt train/val/test split (60/20/20) Ã©s mentÃ©s CSV-be az OUTPUT_DIR/processed mappÃ¡ba.
2. **02_feature_engineering.py** â€” EgyszerÅ± szÃ¶vegstatisztikÃ¡k (word_count, avg_word_len) hozzÃ¡adÃ¡sa Ã©s opcionÃ¡lis Sentence-BERT beÃ¡gyazÃ¡sok mentÃ©se az OUTPUT_DIR/features mappÃ¡ba.
3. **03_train_baseline.py** â€” Baseline szÃ¶vegklasszifikÃ¡ciÃ³s modell: TFâ€‘IDF + LogisticRegression. Modell mentÃ©se (OUTPUT_DIR/models), metrikÃ¡k mentÃ©se (OUTPUT_DIR/reports).
4. **04_train_transformer.py** â€” Transformer alapÃº modell (pl. HuBERT) finomhangolÃ¡sa a jogi szÃ¶vegeken. GPU ajÃ¡nlott! Modell Ã©s tokenizer mentÃ©se (OUTPUT_DIR/models/transformer_model).
5. **05_evaluation.py** â€” KÃ¼lÃ¶n Ã©rtÃ©kelÅ‘ script a baseline modellre a test spliten (OUTPUT_DIR/evaluation).
6. **06_robustness_tests.py** â€” RobusztussÃ¡gi tesztek: zajjal Ã©s csonkolÃ¡ssal mÃ³dosÃ­tott szÃ¶vegeken Ã©rtÃ©keli a baseline modellt (OUTPUT_DIR/robustness).
7. **07_explainability.py** â€” Modell Ã©rtelmezhetÅ‘sÃ©g: top feature-Ã¶k osztÃ¡lyonkÃ©nt, predikciÃ³ magyarÃ¡zatok, hibaelemzÃ©s (OUTPUT_DIR/explainability).

> A `src/run.sh` sorban futtatja az Ã¶sszes `src/*.py` fÃ¡jlt (Ã¡bÃ©cÃ©rendben). Dockerben ez az alapÃ©rtelmezett belÃ©pÃ©si pont.

## ğŸ“„ AdatformÃ¡tum

ElvÃ¡rt minimÃ¡lis sÃ©ma egy elemre:

```json
{
	"data": { "text": "A bekezdÃ©s szÃ¶vegeâ€¦" },
	"annotations": [
		{
			"result": [
				{ "value": { "choices": ["KÃ¶nnyen Ã©rthetÅ‘"] } }
			]
		}
	]
}
```

**MegjegyzÃ©s:** Az elsÅ‘ elem elsÅ‘ vÃ¡lasztÃ¡sa kerÃ¼l felhasznÃ¡lÃ¡sra: `annotations[0].result[0].value.choices[0]`

```
output/
â”œâ”€â”€ processed/
â”‚   â”œâ”€â”€ train.csv               # Training set (60%, szÃ¶vegstatisztikÃ¡kkal)
â”‚   â”œâ”€â”€ val.csv                 # Validation set (20%)
â”‚   â””â”€â”€ test.csv                # Test set (20%)
â”‚
â”œâ”€â”€ features/
â”‚   â”œâ”€â”€ train_word_count_hist.png
â”‚   â”œâ”€â”€ train_avg_word_len_hist.png
â”‚   â”œâ”€â”€ embeddings_train.npy    (ha ENABLE_EMBEDDINGS=true)
â”‚   â”œâ”€â”€ embeddings_val.npy
â”‚   â”œâ”€â”€ embeddings_test.npy
â”‚   â””â”€â”€ embeddings_meta.json
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ baseline_model.pkl      # Sklearn pipeline
â”‚   â”œâ”€â”€ label_mapping.json      # Label â†’ ID mapping
â”‚   â””â”€â”€ transformer_model/      # HuBERT modell
â”‚       â”œâ”€â”€ config.json
â”‚       â”œâ”€â”€ pytorch_model.bin
â”‚       â””â”€â”€ tokenizer files
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ baseline_val_report.json
â”‚   â”œâ”€â”€ baseline_test_report.json
â”‚   â”œâ”€â”€ baseline_test_confusion_matrix.png
â”‚   â”œâ”€â”€ transformer_test_report.json
â”‚   â””â”€â”€ transformer_training_history.png
â”‚
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ baseline_test_report.json
â”‚   â””â”€â”€ baseline_test_confusion_matrix.png
â”‚
â”œâ”€â”€ robustness/
â”‚   â”œâ”€â”€ robustness_results.json
â”‚   â””â”€â”€ robustness_comparison.png
â”‚
â””â”€â”€ explainability/
    â”œâ”€â”€ feature_importance.json
    â”œâ”€â”€ top_features_per_class.png
    â”œâ”€â”€ prediction_explanations.json
    â””â”€â”€ misclassification_analysis.json
```

## âš™ï¸ KÃ¶rnyezeti vÃ¡ltozÃ³k

### AlapvetÅ‘
| VÃ¡ltozÃ³ | AlapÃ©rtelmezett | LeÃ­rÃ¡s |
|---------|----------------|--------|
| `DATA_DIR` | `/app/data` | Input adatok helye |
| `OUTPUT_DIR` | `/app/output` | Kimenetek helye |

### Baseline
| VÃ¡ltozÃ³ | AlapÃ©rtelmezett | LeÃ­rÃ¡s |
|---------|----------------|--------|
| `TFIDF_MAX_FEATURES` | `20000` | Max TF-IDF feature-Ã¶k szÃ¡ma |
| `TFIDF_NGRAM_MAX` | `2` | N-gram felsÅ‘ hatÃ¡r |
| `LR_C` | `1.0` | RegularizÃ¡ciÃ³s paramÃ©ter |

### Transformer
| VÃ¡ltozÃ³ | AlapÃ©rtelmezett | LeÃ­rÃ¡s |
|---------|----------------|--------|
| `TRANSFORMER_MODEL` | `SZTAKI-HLT/hubert-base-cc` | Transformer modell nÃ©v |
| `BATCH_SIZE` | `8` | Batch mÃ©ret (8GB VRAM-hoz) |
| `EPOCHS` | `3` | Epochok szÃ¡ma |
| `LEARNING_RATE` | `2e-5` | TanulÃ¡si rÃ¡ta |
| `MAX_LENGTH` | `512` | Max token hossz |

### Embeddings
| VÃ¡ltozÃ³ | AlapÃ©rtelmezett | LeÃ­rÃ¡s |
|---------|----------------|--------|
| `ENABLE_EMBEDDINGS` | `false` | Sentence-BERT embeddings be/ki |
| `EMBEDDING_MODEL` | `paraphrase-multilingual-MiniLM-L12-v2` | Embedding modell |

## ï¿½ Kimenetek

```
output/
â”œâ”€â”€ processed/          # train/val/test CSV-k
â”œâ”€â”€ features/           # StatisztikÃ¡k, embeddings
â”œâ”€â”€ models/             # baseline_model.pkl, transformer_model/
â”œâ”€â”€ reports/            # MetrikÃ¡k, confusion matrix
â”œâ”€â”€ evaluation/         # Test eredmÃ©nyek
â”œâ”€â”€ robustness/         # RobusztussÃ¡gi tesztek
â””â”€â”€ explainability/     # Feature importance
```

## ğŸ› HibaelhÃ¡rÃ­tÃ¡s

| ProblÃ©ma | MegoldÃ¡s |
|----------|----------|
| `CUDA not available` | EllenÅ‘rizd: `nvidia-smi`, Docker GPU support |
| `CUDA out of memory` | `-e BATCH_SIZE=4` vagy `-e MAX_LENGTH=256` |
| Stratified split hiba | Min. 3-5 pÃ©lda/osztÃ¡ly szÃ¼ksÃ©ges |
| LassÃº futÃ¡s CPU-n | HasznÃ¡lj GPU-t vagy tÃ¶rÃ¶ld `04_train_transformer.py` |
| JSON parsing hiba | EllenÅ‘rizd az AdatformÃ¡tum szekciÃ³t |

## â±ï¸ TeljesÃ­tmÃ©ny

| Modell | Accuracy | Training | GPU | Memory |
|--------|----------|----------|-----|--------|
| Baseline | 60-75% | ~3 min | Nem kell | ~500 MB |
| Transformer | 70-85% | ~40 min | 8GB+ VRAM | ~2-4 GB |

**Teljes pipeline:** ~45-60 min (GPU) | ~6+ Ã³ra (CPU)

## ğŸ“ Licenc

LÃ¡sd: `LICENSE`
